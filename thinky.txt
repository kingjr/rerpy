never mind, write random access code for kutaslab reader
scan (but don't decompress) the file first, which will be very fast,
and then can find any block in constant time. or scan on demand even.
   and maybe have a little global LRU cache to store records so even
     scrolling will be fast (or wait until we need scrolling)
still have a DataSource, but now it just has __getitem__

need a way to save DataSets
  either with or without data
  without data: ask each Recording for an object that when unpickled
    and then called will return the original recording
  with data: for each recording dump the data out and use a special
    InOurProprietaryDataFormatRecording



two levels of metadata on sensors/channels:
  sensor info: position, type, maybe intrinsic units (or implied by
    type)
  channel info:
    relation to sensors, comes in several types:
      raw (e.g. MEG):
      ref'ed (e.g. EEG): one privileged sensor whose name we share,
       plus some linear transformation of other sensor values
      arbitrary linear function: ICA components
    transformations should alter this stuff -- need some way to say
    that channels are changing when calling .transform I guess?

maybe we can store

it would be nice to support fancy "nearby" type queries, like cdbl and
Binlister[1]
[1] http://erpinfo.org/erplab/erplab-documentation/manual/Binlister.html
they can't *directly* replace what cdbl does, because to do that we
would need access to this kind of information in both the query and
the formula, and it's hard to imagine how to extend the formula stuff
to write these kinds of expressions directly in it.
but there should be some nice way to at least find the events so you
can add attributes to them
p.previous_matches(<query>, ignore=<query>, limit=(min_ms, max_ms))
p.next_matches(<query>, ignore=<query>, limit=(min_ms, max_ms))
meaning: the immediately previous/next event (ignoring the ones in
ignore) must match <query>, and occur within the time limits (if
given). (need to put ms into events, but that's no problem. could add
start_time field next to start_tick etc. for querying.)
then these of course could be embedded, inverted, etc.
for the string syntax... probably need to add function call syntax for
this to be reasonable. at least comma doesn't mean anything else for
us.
-- this can be done with SQL, though a touch of trickiness will be
needed to uniquely rename the tables in the self-join.
   http://stackoverflow.com/questions/19094257/in-sql-how-to-query-for-rows-based-on-the-values-in-other-rows-at-a-certain-rel
  SELECT * FROM foo AS foo1 WHERE <foo1 restrictions>
   AND EXISTS
     (SELECT 1 FROM
        (SELECT * FROM foo WHERE <any skip restrictions> AND <near foo1>
         ORDER BY time LIMIT 1 OFFSET <n>) AS foo2
        WHERE <foo2 restrictions>)


if we ever want to support recordings that are aligned but without a
fixed shared sampling rate -- maybe this will happen for EEG/MEG etc.?
-- then recspan_id becomes basically time_base_id, and each actual
recording is oriented relative to a time_base -- annotate with start
time (time base, floating point time), sampling rate (floating point),
and events similarly are placed at particular (time base, floating
point time) locations.
this is enough to, given an event (and a set of channels we care
about) locate the data in all of those channels's at that
event. Don't need extra storage costs and possible rounding headaches
involved in storing/search floating point times arrays because can
calculate them on the fly...

formats:
  Python code for reading .cnt (NeuroScan) files (no license but could
  easily rewrite or email about):
    https://github.com/UMDLinguistics/eeg-cnt/blob/master/cnt2h5.py
    -- uncompressed, allows random seeks (and even mmap as int16 I guess)
  EDF/BDF (C code, BSD):
    http://www.teuniz.net/edflib/
    or trivial to reimplement: http://www.biosemi.com/faq/file_format.htm
    -- uncompresed, allows random seeks (and EDF allows int16 mmap I guess)
  ERPLAB (b/c it would be an excellent first demo to import these and
  let people reproduce their previous analysis):
    http://erpinfo.org/erplab/erplab-documentation/manual/Binlister.html
    http://erpinfo.org/erplab/erplab-documentation/manual/Epoching_Bins.html
      (this has a description at the bottom of how artifacts are
      recorded etc.)
    http://erpinfo.org/erplab/erplab-documentation/manual/Background_and_Structures.html

  ERPLAB is also a useful *export* target for rERP waveforms, for
    plotting etc.

  Some MEG format reader (whatever they use at UMD) (GPL):
    https://github.com/pealco/Cephalo

  Channel location files (with samples!):
    http://sccn.ucsd.edu/eeglab/channellocation.html


qt plotting
drawing:
qpainterpath stores: vector of <double x, double y, small-enum mode>,
so I guess 24 bytes/point, or a factor of 3 expansion over raw data.
display coordinate cache has various fancy stuff in it now (stores
only part of the item, redraws only part), but given the above this
may not be enough to solve the problem directly for giant lines. but
it is the case that all cached stuff goes into the global
QPixmapCache. so i guess probably the thing to do is to have multiple
items, each of which builds a path and then renders it every time it's
painted, and enable the cache for each.
what might work out the same is to just have one giant item, enable
caching (with some caveat about whether this actually works for large
items? there's some code I don't quite understand to silently disable
caching sometimes), and then when redrawing just create the given path
and draw it. Or equivalently, make it part of the background and
enable background caching in the view, which does in fact save just
what's visible, and requests a draw of just the newly exposed part if
the scene shifts. could cache the path too maybe.
or can we listen to the view's motion and just always place a pathitem
in front of it? That would take python out of the rendering loop
entirely for big chunks of the time. I don't see an easy way to listen
to the viewport rectangle (no signal e.g.) but a sneaky way would be
to override the paint method...
no easy way to do scrolling inside a qgraphicsscene, maybe put the
fixed stuff in a different widget and just do the math? or else move
it every time viewport moves? -- it looks like you can put child
widgets on top of a qgraphicsview: http://stackoverflow.com/questions/3683565/how-to-anchor-qgraphicswidget-item-make-them-static-on-qgraphicsview
or for non-interactive things, can just paint them in a qgraphicsview
subclass (drawBackground, drawForeground)
silly display ideas: tooltip giving channel name on each graph. always
place the leftmost point in each line on the center, moving the rest
of the display vertically to match (sort of continuous
baselining). would be horrible for scrolling through quickly changing
values though.

have a special "cals" command that (1) arranges for the given events
to be included in a special bin in all output files, (2) eliminates
the given events from consideration for other stuff (maybe even just
deletes their code and condition entries)

or another way to do this, scoped restrictions?
select <query>
  # indented block
  # <query> is automatically ANDed with any queries within this
  # section

define "groups" as short-hands for certain queries? maybe better to
just add fields.

match code == 12 and condition == 0 as BASE
next with code == 13 within 200-800


wacky idea, just make the input file python code?
  (py2 or py3?)


importing events from eeglab: this page says how to import events
*into* eeglab, and has sample files to do this with, plus points to
the function that lets you export data to csv... so it should have the
right leads for figuring out how this information is stored in the
eeglab structure:
http://sccn.ucsd.edu/wiki/A02:_Importing_Event_Epoch_Info
